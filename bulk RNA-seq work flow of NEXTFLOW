#!/usr/bin/env nextflow

/*
 * Copyright (c) 2016-2018, Centre for Genomic Regulation (CRG) and the authors.
 *
 *   This file is part of 'Tuxedo-NF'.
 *
 *   Tuxedo-NF is free software: you can redistribute it and/or modify
 *   it under the terms of the GNU General Public License as published by
 *   the Free Software Foundation, either version 3 of the License, or
 *   (at your option) any later version.
 *
 *   Tuxedo-NF is distributed in the hope that it will be useful,
 *   but WITHOUT ANY WARRANTY; without even the implied warranty of
 *   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 *   GNU General Public License for more details.
 *
 *   You should have received a copy of the GNU General Public License
 *   along with Tuxedo-NF.  If not, see <http://www.gnu.org/licenses/>.
 */

/*
 * Main Tuxedo-NF pipeline script
 *
 * @authors
 * Evan Floden <evanfloden@gmail.com>
 */

log.info "T U X E D O - N F  ~  version 0.2"
log.info "====================================="
log.info "annotation             : ${params.annotation}"
log.info "fq files               : ${params.reads}"
log.info "output                 : ${params.output}"
log.info "index                  : ${params.index}"
log.info "====================================="
log.info "\n"

/*
 * Input parameters validation
 */

annotation_file               = file(params.annotation)
index_file                    = file(params.index)
index_file1                   = index_file + ".1.ht2"
index_name                    = index_file.getFileName()
index_dir                     = index_file.getParent()


/*
 * validate and create a channel for annotation input files
 */

Channel
    .fromPath ( annotation_file )
    .into { annotations1; annotations2 }
/*
 * Create a channel for read files
 */

if ( params.reads ) {
    Channel
        .fromFilePairs( params.reads, size: -1)
        .ifEmpty { error "Cannot find any reads matching: ${params.reads}" and use_sra is false}
        .set { read_files }
}


// GENOME INDEXING
// ===============

process premade_index {

    input:
    file(index_dir)
    val(index_name)

    output:
    set val(index_name), file("genomeindex") into genome_index

    script:
    //
    // Premade HISAT2 genome index
    //
    """
    mkdir genomeindex
    cp ${index_dir}/${index_name}.*.ht2 genomeindex/.
    """
}

process trim{
    maxForks 10
    publishDir = [path: "${params.output}/trims", mode: 'link', overwrite: 'ture' ]
    tag "reads: $sample_id"

    input:
    set val(sample_id), file(reads) from read_files

    output:
    set val(sample_id), file("${sample_id}_*p_trim.fastq.gz") into fatq_maps

    script:
    //
    // TRIM FASTQ
    //
    def single = reads instanceof Path
    if( single )
       """
	mkdir -p ${params.output}/trims
	/opt/fastp -i ${sample_id}.fastq.gz \
	-w 6 \
	//-f 11 \
	-W 4 -M 30 -r \
        // If the reads ≥ 80 bp, keep the reads with a length greater than 50 bp after trimming; if reads < 80 bp, keep the reads with a length greater than 35 bp after trimming
	-l 50 \
	-o ${sample_id}_p_trim.fastq.gz > ${params.output}/trims/${sample_id}.trim.log 2>&1
       """
   else
        """
	mkdir -p ${params.output}/trims
        /opt/fastp -i ${sample_id}_1.fastq.gz -I ${sample_id}_2.fastq.gz \
        -w 8 \
        // -f 11 -F 11 \
        -W 4 -M 30 -r \
        // If the reads ≥ 80 bp, keep the reads with a length greater than 50 bp after trimming; if reads < 80 bp, keep the reads with a length greater than 35 bp after trimming
	-l 50 \
        -o ${sample_id}_1p_trim.fastq.gz -O ${sample_id}_2p_trim.fastq.gz \
        > ${params.output}/trims/${sample_id}.trim.log 2>&1
        """

}



process mapping {
    maxForks 5
    publishDir = [path: "${params.output}/mapped_sams", mode: 'link', overwrite: 'true' ]
    tag "reads: $sample_id"

    input:
    set val(index_name), file(index_dir) from genome_index
    set val(sample_id), file(reads) from fatq_maps
    file annotation_f from annotations2.first()
    //set val(sample_id), file(input_files) from fatq_maps

    output:
    set val(sample_id), file("${sample_id}.sam") into hisat2_sams
    //file("fastqc_${sample_id}_logs") into fastqc_ch
    file "*.{zip,html,featureCountlog,counts.summary,maplog}" into fastqc_ch
    file("${sample_id}.maplog")
    file("${sample_id}.featureCountlog")
    file("${sample_id}.counts")
    file("${sample_id}.counts.summary")
    script:
    //
    // HISAT2 mapper
    //
    def single = reads instanceof Path
    if( single )
        """
        mkdir fastqc_${sample_id}_logs
        fastqc -o ./ -f fastq -q ${reads}
        /opt/hisat2/hisat2 -p 16 -x ${index_dir}/${index_name} -U ${reads} -S ${sample_id}.sam 2>${sample_id}.maplog
        /opt/subread/bin/featureCounts -T 6 -t exon -g gene_id -a ${annotation_f} -o ${sample_id}.counts  ${sample_id}.sam 2>${sample_id}.featureCountlog
        """
    else
        """
        mkdir fastqc_${sample_id}_logs
        fastqc -o ./ -f fastq -q ${reads}
        /opt/hisat2/hisat2 -p 16 -x ${index_dir}/${index_name} -1 ${reads[0]} -2 ${reads[1]} -S ${sample_id}.sam 2>${sample_id}.maplog
        /opt/subread/bin/featureCounts -T 6 -p -t exon -g gene_id -a ${annotation_f} -o ${sample_id}.counts  ${sample_id}.sam 2>${sample_id}.featureCountlog
        """
}



process sam2bam {
    maxForks 10
    publishDir = [path: "${params.output}/mapped_bams", mode: 'link', overwrite: 'true' ]
    tag "sam2bam: $name"

    input:
    set val(name), file(sam) from hisat2_sams

    output:
    set val(name), file("${name}.bam") into hisat2_bams

    script:
    //
    // SAM to sorted BAM files
    //
    """
    /opt/samtools/samtools view -@ 8 -S -b ${sam} | /opt/samtools/samtools sort -@ 6 -o ${name}.bam -
    """
}

hisat2_bams.into { hisat2_bams1; hisat2_bams2 }

process transcript_abundance {
    maxForks 10
    publishDir = [path: "${params.output}/stringtie_abundances", mode: 'link', overwrite: 'true' ]
    tag "reads: $name"

    input:
    set val(name), file(bam) from hisat2_bams2
    file annotation_f from annotations1.first()

    output:
    file("${name}") into ballgown_data

    script:
    //
    // Estimate abundances of merged transcripts in each sample
    //
    """
    /opt/stringtie/stringtie -e -G ${annotation_f} -p 8 -o ${name}/${name}.gtf -A ${name}/${name}.gene_abund.tab ${bam}
    """
}


process multiqc {
    maxForks 1
    publishDir = [path: "${params.output}/multiqc", mode: 'link', overwrite: 'true' ]
    input:
    file ('mapping/*') from fastqc_ch.collect().ifEmpty([])

    output:
    file "*_report.html" into multiqc_report
    file "*_data"

    script:
    """
    mkdir -p ${params.output}/multiqc
    multiqc .
    """
}

workflow.onComplete {
        println ( workflow.success ? "\nDone! Open the following results in your browser --> $params.output" : "Oops .. something went wrong" )
}
